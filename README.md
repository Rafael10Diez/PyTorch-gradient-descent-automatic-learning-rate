# PyTorch-gradient-descent-automatic-learning-rate
1) General-purpose PyTorch optimizer with Gradient Descent and Adaptive Learning Rates [1].
     - Works for CPUs and GPUs.
     - Supports automatic differentiation for a generic cost function.
     - Input vector `x` is modified in-place.
3) Simple Tic/Toc profiler module.


# Source:
     [1] Battiti, Roberto. (1989). Accelerated backpropagation learning: Two optimization methods. Complex Syst. 3. (https://www.complex-systems.com/abstracts/v03_i04_a02)
